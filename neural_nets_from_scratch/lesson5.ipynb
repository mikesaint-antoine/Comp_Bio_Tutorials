{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb5b87a",
   "metadata": {},
   "source": [
    "# Neural Nets from Scratch in Julia\n",
    "\n",
    "## Lesson 5: Backpropagation for addition (part 2)\n",
    "\n",
    "* In this video we'll finish up the backward pass of the addition operation\n",
    "* [Documentation site here](https://mikesaint-antoine.github.io/SimpleGrad.jl)\n",
    "* [Github repo here](https://github.com/mikesaint-antoine/SimpleGrad.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a797273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backprop! (generic function with 2 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code so far\n",
    "\n",
    "mutable struct Value{opType} <: Number\n",
    "    data::Float64\n",
    "    grad::Float64\n",
    "    op::opType\n",
    "end\n",
    "\n",
    "\n",
    "struct Operation{FuncType, ArgTypes}\n",
    "    op::FuncType\n",
    "    args::ArgTypes\n",
    "end\n",
    "\n",
    "# constructor -- Value(data, grad, op)\n",
    "Value(x::Number) = Value(Float64(x), 0.0, nothing);\n",
    "\n",
    "\n",
    "import Base.show\n",
    "function show(io::IO, value::Value)\n",
    "    print(io, \"Value(\",value.data,\")\")\n",
    "end\n",
    "\n",
    "\n",
    "import Base.==\n",
    "function ==(a::Value, b::Value)\n",
    "     return a===b\n",
    "end\n",
    "\n",
    "\n",
    "import Base.+\n",
    "function +(a::Value, b::Value)\n",
    "\n",
    "    out = a.data + b.data    \n",
    "    result = Value(out, 0.0, Operation(+, (a,b))) # Value(data, grad, op)\n",
    "    return result # this should be a Value\n",
    " \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "backprop!(val::Value{Nothing}) = nothing\n",
    "\n",
    "\n",
    "function backprop!(val::Value{Operation{FunType, ArgTypes}}) where {FunType<:typeof(+), ArgTypes}\n",
    "    \n",
    "    # val = a + b\n",
    "    # update a.grad, b.grad\n",
    "    \n",
    "    val.op.args[1].grad += val.grad\n",
    "    val.op.args[2].grad += val.grad\n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab68bb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backward(a::Value)\n",
    "    \n",
    "    \n",
    "    function build_topo(v::Value, visited=Value[], topo=Value[])\n",
    "    \n",
    "        if !(v in visited)\n",
    "            \n",
    "            push!(visited, v)\n",
    "            \n",
    "            if v.op != nothing\n",
    "                for operand in v.op.args\n",
    "                    \n",
    "                    if operand isa Value\n",
    "                        build_topo(operand, visited, topo)\n",
    "                    end\n",
    "                end \n",
    "            end\n",
    "            \n",
    "            push!(topo, v) \n",
    "            \n",
    "            \n",
    "        end\n",
    "        return topo\n",
    "    end\n",
    "    \n",
    "    \n",
    "    \n",
    "    topo = build_topo(a)\n",
    "    \n",
    "    a.grad = 1\n",
    "    #da/da = 1\n",
    "    \n",
    "    for node in reverse(topo)\n",
    "        backprop!(node)\n",
    "    end\n",
    "    \n",
    "    # trying to get\n",
    "    # Value[y, x, b, a, z, w, c]\n",
    "    # topo = Value[x, y, w, a, b, z, c]\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b46aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = Value(2)\n",
    "y = Value(3)\n",
    "\n",
    "a = Value(1)\n",
    "b = Value(4)\n",
    "\n",
    "w = x + y\n",
    "z = a + b\n",
    "\n",
    "c = w + z\n",
    "\n",
    "backward(c)\n",
    "\n",
    "\n",
    "println(w.grad) #dc/dw\n",
    "println(z.grad) #dc/dz\n",
    "\n",
    "println(a.grad) #dc/da\n",
    "println(b.grad) #dc/db\n",
    "println(x.grad) #dc/dx\n",
    "println(y.grad) #dc/dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d471dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "x = Value(3)\n",
    "y = Value(4)\n",
    "\n",
    "z = x + y\n",
    "w = z + x\n",
    "\n",
    "#dw/dx = 2\n",
    "\n",
    "backward(w)\n",
    "\n",
    "println(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop!() - internal function, called on each variable to update the gradients of the the operands for that variable\n",
    "\n",
    "# backward() - user facing function, performs full backward pass\n",
    "\n",
    "\n",
    "# w = x + y\n",
    "# z = a + b\n",
    "\n",
    "# c = w + z\n",
    "\n",
    "# full backward pass\n",
    "# backward(c)\n",
    "\n",
    "# backprop!(c) - updating w.grad and z.grad\n",
    "# backprop!(w) - updating x.grad and y.grad\n",
    "# backprop!(z) - updating a.grad and b.grad\n",
    "# backprop!(a) - does nothing\n",
    "# backprop!(b) - does nothing\n",
    "# backprop!(x) - does nothing\n",
    "# backprop!(y) - does nothing\n",
    "\n",
    "# chain ruling our way back to x\n",
    "# dc/dx = dc/dw * dw/x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
